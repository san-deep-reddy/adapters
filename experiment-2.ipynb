{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T04:29:37.408684Z","iopub.status.busy":"2024-05-27T04:29:37.408122Z","iopub.status.idle":"2024-05-27T04:29:40.005789Z","shell.execute_reply":"2024-05-27T04:29:40.004675Z","shell.execute_reply.started":"2024-05-27T04:29:37.408653Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'adapters'...\n","remote: Enumerating objects: 2720, done.\u001b[K\n","remote: Counting objects: 100% (1904/1904), done.\u001b[K\n","remote: Compressing objects: 100% (815/815), done.\u001b[K\n","remote: Total 2720 (delta 1344), reused 1253 (delta 1034), pack-reused 816\u001b[K\n","Receiving objects: 100% (2720/2720), 9.78 MiB | 33.48 MiB/s, done.\n","Resolving deltas: 100% (1678/1678), done.\n"]}],"source":["!git clone https://github.com/san-deep-reddy/adapters.git"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T04:29:40.008062Z","iopub.status.busy":"2024-05-27T04:29:40.007761Z","iopub.status.idle":"2024-05-27T04:30:00.611215Z","shell.execute_reply":"2024-05-27T04:30:00.610250Z","shell.execute_reply.started":"2024-05-27T04:29:40.008032Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-27 04:29:51.783254: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-27 04:29:51.783356: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-27 04:29:51.936084: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import sys, torch\n","sys.path.append(\"/kaggle/working/adapters/src/\")\n","import adapters\n","import numpy as np\n","import pandas as pd\n","import torch.nn as nn\n","import adapters.composition as ac\n","from adapters.composition import Fuse\n","from adapters.heads import PredictionHead\n","from adapters import AutoAdapterModel, AdapterTrainer, SeqBnConfig\n","from transformers import AutoTokenizer, TrainingArguments, EvalPrediction, default_data_collator, Trainer\n","from datasets import Dataset, load_dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T04:30:00.612990Z","iopub.status.busy":"2024-05-27T04:30:00.612394Z","iopub.status.idle":"2024-05-27T04:30:06.853196Z","shell.execute_reply":"2024-05-27T04:30:06.852200Z","shell.execute_reply.started":"2024-05-27T04:30:00.612964Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62bb39b322664fe39044d2da9d2d0d68","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.71k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f47c24cbdbc4b97a5b2ca32bb0fa787","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/558M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"193a2e29a98047eeb36917e8faf32d26","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/331 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9216cee31994066bf688c970616ab7d","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"303452bab383433eb9e2947f59562aad","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6a14b21cffd4c8ea50026105ad73673","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f03d5f898184180b6970350040ab172","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model_path = \"mse30/bart-base-finetuned-pubmed\"\n","model = AutoAdapterModel.from_pretrained(model_path)\n","tokenizer = AutoTokenizer.from_pretrained(model_path)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T04:30:06.855514Z","iopub.status.busy":"2024-05-27T04:30:06.855209Z","iopub.status.idle":"2024-05-27T04:30:07.131877Z","shell.execute_reply":"2024-05-27T04:30:07.130980Z","shell.execute_reply.started":"2024-05-27T04:30:06.855489Z"},"trusted":true},"outputs":[],"source":["import copy\n","model_copy = copy.deepcopy(model)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T04:30:07.133308Z","iopub.status.busy":"2024-05-27T04:30:07.132995Z","iopub.status.idle":"2024-05-27T04:30:07.189791Z","shell.execute_reply":"2024-05-27T04:30:07.189122Z","shell.execute_reply.started":"2024-05-27T04:30:07.133284Z"},"trusted":true},"outputs":[],"source":["seq_config = SeqBnConfig(reduction_factor=16, use_gating=True)\n","model.add_adapter(\"adapter2\", config=seq_config)\n","model.delete_head('default')\n","model.add_multiple_choice_head(\"adapter2\", layers=2, num_choices=1)\n","model.train_adapter(['adapter2'])"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T04:30:07.191644Z","iopub.status.busy":"2024-05-27T04:30:07.191178Z","iopub.status.idle":"2024-05-27T04:30:07.198423Z","shell.execute_reply":"2024-05-27T04:30:07.197270Z","shell.execute_reply.started":"2024-05-27T04:30:07.191596Z"},"trusted":true},"outputs":[],"source":["# import json\n","# import pandas as pd\n","# import numpy as np\n","\n","# json_file_path = \"/kaggle/input/negative-samples/negative_samples_count64.json\"\n","# with open(json_file_path, 'r') as file:\n","#     negative_samples = json.load(file)\n","\n","# num_negative_samples = 64\n","# batch_size = (1 + num_negative_samples) * 4\n","# num_positive_samples_per_batch = batch_size // (1 + num_negative_samples)\n","\n","# df_list = []\n","\n","# # Define the relationships\n","# relationships = [\"interacts with\", \"is related to\", \"interacts\", \"has function\", \"is a\", \"treats\"]\n","\n","# # Generate samples from negative_samples\n","# for relation in relationships:\n","#     for entity1, values in negative_samples.get(relation, {}).items():\n","#         for entity2, negative_entities in values.items():\n","#             samples = [f\"{entity1} {relation} {entity2}\"]\n","#             samples.extend([f\"{entity1} {relation} {neg_entity}\" for neg_entity in negative_entities[:num_negative_samples]])\n","#             df_list.append(samples)\n","\n","# # Shuffle the samples before creating the DataFrame\n","# random.shuffle(df_list)\n","\n","# # Flatten the list of lists\n","# flattened_list = [item for sublist in df_list for item in sublist]\n","\n","# # Create a DataFrame from the flattened list\n","# df = pd.DataFrame(flattened_list, columns=['text'])\n","\n","# # Generate labels pattern\n","# pattern = [1] + [0]*num_negative_samples\n","# labels = (pattern * (len(df) // len(pattern) + 1))[:len(df)]\n","\n","# # Add labels to the DataFrame\n","# df['labels'] = labels\n","\n","# def generate_batch_indices(start_index, num_positive_samples, num_negative_samples, batch_size, max_index):\n","#     indices = []\n","#     for i in range(num_positive_samples):\n","#         idx = start_index + i * (num_negative_samples + 1)\n","#         if idx < max_index:\n","#             indices.append(idx)\n","#     for j in range(1, num_negative_samples + 1):\n","#         for i in range(num_positive_samples):\n","#             idx = start_index + i * (num_negative_samples + 1) + j\n","#             if idx < max_index:\n","#                 indices.append(idx)\n","#     return indices\n","\n","# # Generate indices for all batches\n","# all_indices = []\n","# max_index = len(df)\n","# for start_index in range(0, max_index, batch_size):\n","#     batch_indices = generate_batch_indices(start_index, num_positive_samples_per_batch, num_negative_samples, batch_size, max_index)\n","    \n","#     # Check if the batch has the required number of positive samples\n","#     if len(batch_indices) == batch_size:\n","#         all_indices.extend(batch_indices)\n","\n","# # Reorder the DataFrame based on the generated indices\n","# df = df.iloc[all_indices].reset_index(drop=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T04:30:07.199771Z","iopub.status.busy":"2024-05-27T04:30:07.199470Z","iopub.status.idle":"2024-05-27T04:30:39.572856Z","shell.execute_reply":"2024-05-27T04:30:39.572024Z","shell.execute_reply.started":"2024-05-27T04:30:07.199748Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"/kaggle/input/negative-samples/64negsamples.csv\")\n","num_negative_samples = 64\n","batch_size = (1 + num_negative_samples) * 4\n","num_positive_samples_per_batch = batch_size // (1 + num_negative_samples)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T04:30:42.727100Z","iopub.status.busy":"2024-05-27T04:30:42.726307Z","iopub.status.idle":"2024-05-27T04:31:06.099687Z","shell.execute_reply":"2024-05-27T04:31:06.098811Z","shell.execute_reply.started":"2024-05-27T04:30:42.727055Z"},"trusted":true},"outputs":[],"source":["def get_train_test_sizes(df_length, batch_size, num_negative_samples):\n","    train_split = 0.8  # Desired train split\n","    test_split = 0.2   # Desired test split\n","\n","    # Calculate train and test sizes\n","    train_size = int(np.floor(train_split * df_length / (batch_size * (1 + num_negative_samples))) * batch_size * (1 + num_negative_samples))\n","    test_size = int(np.floor(test_split * df_length / (batch_size * (1 + num_negative_samples))) * batch_size * (1 + num_negative_samples))\n","\n","    return train_size, test_size\n","\n","# Usage\n","train_size, test_size = get_train_test_sizes(len(df), batch_size, num_negative_samples)\n","dataset = Dataset.from_pandas(df).train_test_split(train_size=train_size, test_size=test_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T04:31:06.101640Z","iopub.status.busy":"2024-05-27T04:31:06.101318Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d39479c01984378a85c75b5a9dd9de9","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/25012000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["def encode_batch(batch):\n","    \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n","    return tokenizer(batch[\"text\"], padding=True, return_tensors=\"pt\")\n","\n","dataset = dataset.map(encode_batch, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["max_token_length_train = max([len(batch[\"input_ids\"]) for batch in dataset[\"train\"]])\n","print(max_token_length_train)\n","max_token_length_eval = max([len(batch[\"input_ids\"]) for batch in dataset[\"test\"]])\n","print(max_token_length_eval)\n","max_token_length = max(max_token_length_train, max_token_length_eval)\n","print(max_token_length)\n","\n","def pad_to_max_length(example):\n","    input_ids = torch.tensor(example[\"input_ids\"])\n","    attention_mask = torch.tensor(example[\"attention_mask\"])\n","    padded_input_ids = torch.nn.functional.pad(input_ids, (0, max_token_length - input_ids.shape[0]), value=0)\n","    padded_attention_mask = torch.nn.functional.pad(attention_mask, (0, max_token_length - attention_mask.shape[0]), value=0)\n","    return {\"input_ids\": padded_input_ids, \"attention_mask\": padded_attention_mask, \"labels\": example[\"labels\"]}\n","\n","dataset[\"train\"] = dataset[\"train\"].map(pad_to_max_length)\n","dataset[\"test\"] = dataset[\"test\"].map(pad_to_max_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import EarlyStoppingCallback\n","\n","early_stopping_callback = EarlyStoppingCallback(\n","    early_stopping_patience=3,  # Stop training after 3 epochs without improvement\n","    early_stopping_threshold=0.001  # Function to calculate the monitored quantity (e.g., evaluation loss)\n",")\n","\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./\",\n","    num_train_epochs=100,\n","    per_device_train_batch_size=520,\n","    per_device_eval_batch_size=520,\n","    learning_rate=2e-5,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    report_to=\"tensorboard\",\n","    logging_strategy=\"epoch\",\n","load_best_model_at_end = True,\n","do_train true\n","do_ev)\n","\n","def compute_accuracy(p: EvalPrediction):\n","    print(p, \"\\n\", type())\n","    print(p.predictions, \"\\n\", p.redictions.shape)\n","    print(p.label_ids, \"\\n\")\n","    preds = np.argmax(p.predictions[0], axis=1).flatten()\n","    return {\"acc\": (preds == p.label_ids).mean()}\n","\n","trainer = AdapterTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","#     compute_metrics=compute_accuracy,\n","    #callbacks=[early_stopping_callback]\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4827394,"sourceId":8525795,"sourceType":"datasetVersion"}],"dockerImageVersionId":30683,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
